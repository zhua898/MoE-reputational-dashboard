---
title: "MoE-reputational-dashboard"
output: html_document
date: "2023-08-10"
---

Initiate library
```{r}
library(syuzhet)
library(tidytext)
library(dplyr)
library(readxl)
library(tidyverse)
library(tm)
library(topicmodels)
library(ggplot2)
library(LDAvis)
library(textTinyR)
library(stm)
library(proxy)
library(BTM)
library(shiny)
library(tidyr)


```


define the data frame
```{r}
df <- read_excel("100_result.xlsx")


```


Machine learning method
```{r}
get_recoded_sentiment <- function(text, method) {
  sentiment_score <- get_sentiment(text, method = method)
  #assign value to positive, neutral and negative
  recoded_sentiment <- case_when(
    sentiment_score > 0 ~ 1,
    sentiment_score == 0 ~ 0,
    sentiment_score < 0 ~ -1
  )
  
  return(recoded_sentiment)
}

methods <- c("syuzhet", "bing", "afinn", "nrc")

for (method in methods) {
  df[[paste0(method, "_recode_sentiment")]] <- sapply(df$`Hit Sentence`, get_recoded_sentiment, method = method)
}

#bar charts display
for (method in methods) {
  print(paste("Counts for method:", method))
  sentiment_counts <- table(df[[paste0(method, "_recode_sentiment")]])
  print(as.data.frame(sentiment_counts))
  
  bar_chart <- ggplot(as.data.frame(sentiment_counts), aes(x = Var1, y = Freq)) +
    geom_bar(stat = "identity", fill = c("red", "grey", "blue")) +
    labs(title = paste("Sentiment Distribution using", method), x = "Sentiment", y = "Count") +
    scale_x_discrete(labels = c("-1" = "Negative", "0" = "Neutral", "1" = "Positive")) +
    geom_text(aes(label = Freq), vjust = -0.5)
  
  print(bar_chart)
  
  
}






```



Coherence models for both web and tweet data
```{r}
# Create a corpus
corpus <- Corpus(VectorSource(df$combined_content))

# Preprocess the data
clean_corpus <- tm_map(corpus, content_transformer(tolower))
clean_corpus <- tm_map(clean_corpus, removePunctuation)
clean_corpus <- tm_map(clean_corpus, removeNumbers)
clean_corpus <- tm_map(clean_corpus, stripWhitespace)
extended_stopwords <- c(stopwords("en"), "\"", "-", "'s", "also", "like",'"',"'" )
clean_corpus <- tm_map(clean_corpus, removeWords, extended_stopwords)
clean_corpus <- tm_map(clean_corpus, stemDocument)
clean_corpus <- tm_map(clean_corpus, removeWords, "\\b\\w{1,2}\\b")





# Create a Document-Term Matrix (DTM)
dtm <- DocumentTermMatrix(clean_corpus)
dtm <- dtm[rowSums(as.matrix(dtm)) > 0, ]


k <- 10  # Number of topics. Adjust this as per your requirement.
lda_model <- LDA(dtm, k = k)

# Get top terms for topics
top_terms <- apply(topics(lda_model, 10), MARGIN = 2, FUN = order, decreasing = TRUE)

# Get term matrix
terms_matrix <- as.matrix(dtm)

# Compute coherence
coherence_scores <- numeric(k)
for (topic in 1:k) {
    term_pairs <- combn(top_terms[, topic], 2)
    score <- sum(apply(term_pairs, 2, function(pair) {
        i <- pair[1]
        j <- pair[2]
        Dij <- sum(terms_matrix[, i] & terms_matrix[, j])
        Di <- sum(terms_matrix[, i])
        if (Di == 0) return(0)
        (log1p(Dij) - log(Di)) 
    }))
    coherence_scores[topic] <- score
}

matrix_dtm <- as.matrix(dtm)
vocab <- colnames(matrix_dtm)

phi <- posterior(lda_model)$terms
theta <- posterior(lda_model)$topics

print(head(terms_lda))

vis_data <- createJSON(phi = phi, 
                       theta = theta, 
                       doc.length = rowSums(matrix_dtm),
                       vocab = vocab,
                       term.frequency = colSums(matrix_dtm))



serVis(vis_data)









```



Coherence score for both web and tweet data.
```{r}
coherence_df <- data.frame(Topic = 1:k, Coherence = coherence_scores)
ggplot(coherence_df, aes(x = Topic, y = Coherence)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Coherence Scores per Topic", x = "Topic", y = "Coherence Score") +
  theme_minimal()





```




BTM model for tweet data (suitable for short text)
```{r}
# Define stop words and add custom ones
stop_words <- stopwords("en")
custom_stop_words <- c("on", "the", "and", "is", "of", "ministry", "since", "NULL"
                       ,"&", "nz", " ")
stop_words <- union(stop_words, custom_stop_words)

generate_biterms <- function(tokenized_sentence) {
  biterms_list <- list()
  
  # For every word in the sentence
  for (i in 1:(length(tokenized_sentence) - 1)) {
    for (j in (i + 1):length(tokenized_sentence)) {
      biterm <- sort(c(tokenized_sentence[i], tokenized_sentence[j]))
      biterms_list <- c(biterms_list, list(biterm))
    }
  }
  
  return(biterms_list)
}

# Tokenize sentences and remove stop words
word_list <- lapply(df$`Hit Sentence`, function(sentence){
  words <- unlist(strsplit(as.character(sentence), " "))
  cleaned_words <- words[!tolower(words) %in% stop_words]
  return(cleaned_words)
})

# Generate biterms
biterms <- unlist(lapply(word_list, generate_biterms), recursive = FALSE)

biterm_freq <- table(unlist(lapply(biterms, paste0, collapse=" & ")))

# Top 20 biterms
top_biterms <- head(sort(biterm_freq, decreasing = TRUE), 60)

# Plot
top_biterms_df <- as.data.frame(top_biterms)
colnames(top_biterms_df) <- c("Biterms", "Freq")
plot <- ggplot(top_biterms_df, aes(x = Biterms, y = Freq)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  labs(title = "Top 60 Biterms", x = "Biterms", y = "Frequency") + 
  theme(axis.text.y = element_text(size = 8))  # Reduce the font size for y-axis text

print(plot)
ggsave("biterms_plot.png", plot, width = 10, height = 10)






```



Demo interactive dashboard using shiny
```{r}

# Shiny User Interface
ui <- fluidPage(
  titlePanel("MoE Reputational Dashboard"),
  
  mainPanel(
    tabsetPanel(
      tabPanel("Top 10 Cities by Count", plotOutput("cityPlot", width = "100%", height = "500px")),
      tabPanel("Most Common Words Count", plotOutput("wordPlot", width = "100%", height = "700px")),
      tabPanel("Twitter Count", plotOutput("twitterPlot", width = "100%", height = "500px")),
      tabPanel("Top 10 Twitter Followers", plotOutput("followersPlot", width = "100%", height = "500px")),
      verbatimTextOutput("errorText")
    )
  )
)

# Shiny Server
server <- function(input, output) {

  # Top 10 Cities Plot
  observe({
    result <- try({
      top_cities <- df %>%
        group_by(City) %>%
        summarise(Count = n()) %>%
        ungroup() %>%
        top_n(10, Count)
      
      p <- ggplot(top_cities, aes(x = reorder(City, -Count), y = Count)) +
        geom_bar(stat = "identity") +
        geom_text(aes(label = Count), vjust = -0.5) + 
        theme_minimal() +
        labs(title = "Top 10 Cities by Count", x = "City", y = "Count")
      
      output$cityPlot <- renderPlot({ print(p) })
    }, silent = TRUE)
    
    if(inherits(result, "try-error")) {
      output$errorText <- renderText({ as.character(result) })
    }
  })

  # Most Common Words Plot
  observe({
    result <- try({
      p <- ggplot(df, aes(x = reorder(`Most Common Words`, -`Count for most common words`), y = `Count for most common words`)) +
        geom_bar(stat = "identity") +
        aes(label = `Count for most common words`) +
        theme_minimal() +
        labs(title = "Most Common Words Count", x = "Word", y = "Count") +
        coord_flip()
      
      output$wordPlot <- renderPlot({ print(p) })
    }, silent = TRUE)
    
    if(inherits(result, "try-error")) {
      output$errorText <- renderText({ as.character(result) })
    }
  })

  # Twitter Count Plot
  observe({
    result <- try({
      twitter_counts <- df %>%
        group_by(is_twitter) %>%
        summarise(Count = n()) %>%
        ungroup()
      
      p <- ggplot(twitter_counts, aes(x = as.factor(is_twitter), y = Count)) +
        geom_bar(stat = "identity") +
        geom_text(aes(label = Count), vjust = -0.5) +
        theme_minimal() +
        labs(title = "Twitter Source Count", x = "Is Twitter", y = "Count")
      
      output$twitterPlot <- renderPlot({ print(p) })
    }, silent = TRUE)
    
    if(inherits(result, "try-error")) {
      output$errorText <- renderText({ as.character(result) })
    }
  })
  
  # Top 10 Twitter Followers Plot
  observe({
  result <- try({
    # Get top 10 unique tweet_ids based on Twitter Followers count
    top_followers <- df %>%
      arrange(desc(`Twitter Followers`)) %>%
      select(`Twitter Followers`, `Tweet Id`) %>%
      distinct(`Tweet Id`, .keep_all = TRUE) %>%
      head(10)
    
    p <- ggplot(top_followers, aes(x = as.factor(`Tweet Id`), y = `Twitter Followers`)) +
      geom_bar(stat = "identity") +
      geom_text(aes(label = `Twitter Followers`), vjust = -0.5) +
      theme_minimal() +
      labs(title = "Top 10 Twitter Followers by Tweet Id", x = "Tweet Id", y = "Followers Count") +
      coord_flip()
    
    output$followersPlot <- renderPlot({ print(p) })
  }, silent = TRUE)
  
  if(inherits(result, "try-error")) {
    output$errorText <- renderText({ as.character(result) })
  }
})
  
}

# Run the application 
shinyApp(ui = ui, server = server)





```






























